{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b03c7f9-3dd9-4fb1-b32a-e5796a0b50d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:22.513799Z",
     "iopub.status.busy": "2025-03-27T04:07:22.513799Z",
     "iopub.status.idle": "2025-03-27T04:07:23.444175Z",
     "shell.execute_reply": "2025-03-27T04:07:23.443643Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336c12a-4acf-4d06-915e-1335f4598ceb",
   "metadata": {},
   "source": [
    "# 1. Import Special Admit Foundation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee08755-712c-44cb-a4b9-066cb94f7844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.446200Z",
     "iopub.status.busy": "2025-03-27T04:07:23.446200Z",
     "iopub.status.idle": "2025-03-27T04:07:23.456862Z",
     "shell.execute_reply": "2025-03-27T04:07:23.456862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "   StudentID         Ethnicity     AcYr  EnrollType AdmitType HighSchool  \\\n",
      "0          1            Latinx  2023-24  Concurrent      Conc          A   \n",
      "1          2             Asian  2023-24        CCAP      Dual          B   \n",
      "2          3   Multi-Ethnicity  2023-24  Concurrent      Conc          C   \n",
      "3          4            Latinx  2023-24  Concurrent      Conc          D   \n",
      "4          5  African American  2023-24  Concurrent      Conc          D   \n",
      "\n",
      "               District College  \n",
      "0  High School District    ABCD  \n",
      "1  High School District    ABCD  \n",
      "2  High School District    ABCD  \n",
      "3  High School District    ABCD  \n",
      "4  High School District    ABCD  \n"
     ]
    }
   ],
   "source": [
    "# Define the file path to import Special Admit Foundation Data\n",
    "# Replace \"sampledrive\\samplefolder\\samplefile\" with correct path (\"drive\\folder\\file\")\n",
    "file_path = r'C:\\Project Files\\CDE 2024 Python\\RP_Conference_Share\\Special Admit Foundation_sample.csv'\n",
    "\n",
    "#check to see if the file path exists  \n",
    "print(os.path.exists(file_path))  # Return \"True\" or \"Flase\"\n",
    "\n",
    "# Read the file into a DataFrame named \"df_ecc_2324\"\n",
    "# Assuming the file is delimited by a specific character, for example, a comma. \n",
    "# Adjust the delimiter as needed.\n",
    "df_ecc_2324 = pd.read_csv(file_path, delimiter=',', low_memory=False)  # Change delimiter if necessary\n",
    "\n",
    "# (Optional) Display the first few rows and the shape of the DataFrame to verify\n",
    "print(df_ecc_2324.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e33fd-95cd-4c2a-91b9-fee2418c8ede",
   "metadata": {},
   "source": [
    "### Check on Required Columns/Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f855f3-d3f5-47aa-bb33-ccafd27348c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.456862Z",
     "iopub.status.busy": "2025-03-27T04:07:23.456862Z",
     "iopub.status.idle": "2025-03-27T04:07:23.464736Z",
     "shell.execute_reply": "2025-03-27T04:07:23.464736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required columns are present.\n",
      "All required 'EnrollType' values are present.\n",
      "All required 'AdmitType' values are present.\n",
      "Data validation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Verify the required columns and values for processing\n",
    "\n",
    "# Required column names\n",
    "required_columns = ['StudentID', 'Ethnicity', 'AcYr', 'AdmitType', 'EnrollType', 'HighSchool']\n",
    "\n",
    "# Check for missing columns\n",
    "missing_columns = [col for col in required_columns if col not in df_ecc_2324.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "else:\n",
    "    print(\"All required columns are present.\")\n",
    "\n",
    "# Verify required values in 'EnrollType'\n",
    "required_enroll_types = {\"NCD\", \"CCAP\", \"Concurrent\"}\n",
    "actual_enroll_types = set(df_ecc_2324['EnrollType'].unique())\n",
    "missing_enroll_types = required_enroll_types - actual_enroll_types\n",
    "if missing_enroll_types:\n",
    "    raise ValueError(f\"Missing required values in 'EnrollType': {missing_enroll_types}\")\n",
    "else:\n",
    "    print(\"All required 'EnrollType' values are present.\")\n",
    "\n",
    "# Verify required values in 'AdmitType'\n",
    "required_admit_types = {\"Conc\", \"Dual\"}\n",
    "actual_admit_types = set(df_ecc_2324['AdmitType'].unique())\n",
    "missing_admit_types = required_admit_types - actual_admit_types\n",
    "if missing_admit_types:\n",
    "    raise ValueError(f\"Missing required values in 'AdmitType': {missing_admit_types}\")\n",
    "else:\n",
    "    print(\"All required 'AdmitType' values are present.\")\n",
    "\n",
    "# Optionally rename columns if needed\n",
    "i_renameCol = 0  # Set to 1 if renaming is required\n",
    "\n",
    "if i_renameCol == 1:\n",
    "    # Define renaming map\n",
    "    rename_dict = {\n",
    "        'OldColumnName1': 'NewColumnName1',\n",
    "        'OldColumnName2': 'NewColumnName2',\n",
    "        'OldColumnName3': 'NewColumnName3',\n",
    "        # Add more mappings if needed\n",
    "    }\n",
    "    \n",
    "    # Rename columns\n",
    "    df_ecc_2324 = df_ecc_2324.rename(columns=rename_dict)\n",
    "\n",
    "    # Display updated dataframe\n",
    "    print(\"Updated Dataframe Preview:\")\n",
    "    print(df_ecc_2324.head())\n",
    "\n",
    "# Output to confirm successful validation\n",
    "print(\"Data validation completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de58ce1-713d-4968-a0e1-4e619a7d7d09",
   "metadata": {},
   "source": [
    "# 2. Aggragate Students by 'AcYr', 'EnrollType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04eeaa43-8ea5-4df1-99ff-50ff5a1c9ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.466498Z",
     "iopub.status.busy": "2025-03-27T04:07:23.466498Z",
     "iopub.status.idle": "2025-03-27T04:07:23.478992Z",
     "shell.execute_reply": "2025-03-27T04:07:23.478992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AcYr  ABCD_CCAP_Total  ABCD_Concurrent_Total  ABCD_NCD_Total  \\\n",
      "0  2021-22            236.0                    9.0           192.0   \n",
      "1  2022-23             63.0                    3.0           166.0   \n",
      "2  2023-24            374.0                   45.0            50.0   \n",
      "\n",
      "   ABCD_SA_Total  \n",
      "0            437  \n",
      "1            232  \n",
      "2            469  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter out rows with missing values in the 'HighSchool' column.\n",
    "# Students without high school information are excluded from the analysis.\n",
    "filtered_data = df_ecc_2324.dropna(subset=['HighSchool'])\n",
    "\n",
    "# Step 2: Aggregate the number of unique students ('StudentID') by 'AcYr' (Academic Year) and 'EnrollType'.\n",
    "aggregated_data = filtered_data.groupby(['AcYr', 'EnrollType']).agg({'StudentID': 'nunique'}).reset_index()\n",
    "\n",
    "# Step 3: Rename the aggregated 'StudentID' column to 'HeadCount' to represent the student count.\n",
    "aggregated_data = aggregated_data.rename(columns={'StudentID': 'HeadCount'})\n",
    "\n",
    "# Step 4: Pivot the aggregated data to a wide format with 'EnrollType' as columns and student counts ('HeadCount') as values.\n",
    "wide_table_1 = aggregated_data.pivot_table(index='AcYr', columns=['EnrollType'], values='HeadCount', fill_value=0)\n",
    "\n",
    "# Step 5: Aggregate the number of unique students ('StudentID') by 'AcYr' to get the total headcount for all special admits (SA), across all 'EnrollType'.\n",
    "temp = filtered_data.groupby(['AcYr']).agg({'StudentID': 'nunique'})\n",
    "\n",
    "# Step 6: Rename the aggregated 'StudentID' column in the temporary table to 'SA' to represent special admit totals.\n",
    "temp = temp.rename(columns={'StudentID': 'SA'})\n",
    "\n",
    "# Step 7: Combine the aggregated 'EnrollType' data and the 'SA' totals into a single wide-format table.\n",
    "wide_table_1 = pd.concat([wide_table_1, temp], axis=1)\n",
    "\n",
    "# Step 8: Replace \"ABCD\" with your college Abbreviation (e.g., \"SDCCD\").\n",
    "# Add \"ABCD_' as a prefix and '_Total' as a suffix to all column names to standardize the naming format.\n",
    "wide_table_1.columns = ['ABCD_' + ''.join(col).strip() + '_Total' for col in wide_table_1.columns.values]\n",
    "\n",
    "# Step 9: Reset the index to move 'AcYr' from the index to a regular column for better accessibility.\n",
    "wide_table_1.reset_index(inplace=True)\n",
    "\n",
    "# (Optional) Display the first few rows and the shape of the final wide-format table for verification.\n",
    "# Uncomment the lines below to inspect the output.\n",
    "print(wide_table_1.head())\n",
    "# print(wide_table_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d1c7f-0672-4150-bff9-68fe4b1c069b",
   "metadata": {},
   "source": [
    "# 3: Aggregate students by'AcYr', 'EnrollType', and 'Ethnicity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e911aa3-7d8a-4846-95b5-0f29f49fd942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.480519Z",
     "iopub.status.busy": "2025-03-27T04:07:23.480519Z",
     "iopub.status.idle": "2025-03-27T04:07:23.497328Z",
     "shell.execute_reply": "2025-03-27T04:07:23.497328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AcYr  ABCD_CCAP_African American  ABCD_CCAP_Asian  ABCD_CCAP_Filipino  \\\n",
      "0  2021-22                        11.0             43.0                39.0   \n",
      "1  2022-23                         4.0             12.0                 9.0   \n",
      "2  2023-24                        28.0             76.0                44.0   \n",
      "\n",
      "   ABCD_CCAP_Latinx  ABCD_CCAP_Multi-Ethnicity  ABCD_CCAP_Native American  \\\n",
      "0              74.0                       17.0                        0.0   \n",
      "1              23.0                        5.0                        0.0   \n",
      "2             112.0                       30.0                        2.0   \n",
      "\n",
      "   ABCD_CCAP_Pacific Islander  ABCD_CCAP_Unreported  ABCD_CCAP_White  ...  \\\n",
      "0                         0.0                   1.0             51.0  ...   \n",
      "1                         1.0                   3.0              6.0  ...   \n",
      "2                         2.0                   4.0             76.0  ...   \n",
      "\n",
      "   ABCD_NCD_White  ABCD_SA_African American  ABCD_SA_Asian  ABCD_SA_Filipino  \\\n",
      "0            39.0                      20.0           70.0              76.0   \n",
      "1            22.0                      13.0           40.0              36.0   \n",
      "2            17.0                      31.0           83.0              50.0   \n",
      "\n",
      "   ABCD_SA_Latinx  ABCD_SA_Multi-Ethnicity  ABCD_SA_Native American  \\\n",
      "0           131.0                     45.0                      0.0   \n",
      "1            88.0                     18.0                      0.0   \n",
      "2           143.0                     42.0                      2.0   \n",
      "\n",
      "   ABCD_SA_Pacific Islander  ABCD_SA_Unreported  ABCD_SA_White  \n",
      "0                       0.0                 3.0           92.0  \n",
      "1                       1.0                 6.0           30.0  \n",
      "2                       2.0                 7.0          109.0  \n",
      "\n",
      "[3 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate students by 'AcYr', 'EnrollType', and 'Ethnicity'.\n",
    "aggregated_data = filtered_data.groupby(['AcYr', 'EnrollType', 'Ethnicity']).agg({'StudentID': 'nunique'}).reset_index()\n",
    "\n",
    "# Rename the 'StudentID' column to 'HeadCount' to indicate the number of unique students.\n",
    "aggregated_data = aggregated_data.rename(columns={'StudentID': 'HeadCount'})\n",
    "\n",
    "# Pivot the aggregated data to a wide format with combined 'EnrollType' and 'Ethnicity' as column headers.\n",
    "wide_table_2 = aggregated_data.pivot_table(index='AcYr', columns=['EnrollType', 'Ethnicity'], values='HeadCount', fill_value=0)\n",
    "\n",
    "# Rename columns by combining 'EnrollType' and 'Ethnicity' into a single string and adding the 'ABCD_' prefix.\n",
    "wide_table_2.columns = ['ABCD_' + '_'.join(col).strip() for col in wide_table_2.columns.values]\n",
    "\n",
    "# Aggregate students by 'AcYr' and 'Ethnicity' to get the headcounts of all special admit (SA) students by ethnicity.\n",
    "temp = filtered_data.groupby(['AcYr', 'Ethnicity']).agg({'StudentID': 'nunique'})\n",
    "\n",
    "# Rename the 'StudentID' column in the temporary dataframe to 'HeadCount'.\n",
    "temp = temp.rename(columns={'StudentID': 'HeadCount'})\n",
    "\n",
    "# Pivot the temporary data to a wide format with 'Ethnicity' as column headers.\n",
    "temp = temp.pivot_table(index='AcYr', columns='Ethnicity', values='HeadCount', fill_value=0)\n",
    "\n",
    "# Rename columns in the temporary dataframe by adding the 'ABCD_SA_' prefix to the ethnicity names.\n",
    "temp.columns = ['ABCD_SA_' + ''.join(col).strip() for col in temp.columns.values]\n",
    "\n",
    "# Combine the two aggregated dataframes (wide_table_2 and temp) side-by-side.\n",
    "wide_table_2 = pd.concat([wide_table_2, temp], axis=1)\n",
    "\n",
    "# Reset the index to make 'AcYr' a regular column.\n",
    "wide_table_2.reset_index(inplace=True)\n",
    "\n",
    "# (Optional) Display the first few rows and the shape of the final wide-format table for verification.\n",
    "# Uncomment the lines below to inspect the output.\n",
    "print(wide_table_2.head())\n",
    "#print(wide_table_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03659adb-5364-41dd-8f89-5109990701f1",
   "metadata": {},
   "source": [
    "# 4. Aggragate Students by 'AcYr', 'AdmitType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5c89a7-fb20-491e-ba24-c1c0fd4d58ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.497328Z",
     "iopub.status.busy": "2025-03-27T04:07:23.497328Z",
     "iopub.status.idle": "2025-03-27T04:07:23.508421Z",
     "shell.execute_reply": "2025-03-27T04:07:23.508421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AcYr  ABCD_Conc_Total  ABCD_Dual_Total\n",
      "0  2021-22             15.0            422.0\n",
      "1  2022-23              4.0            228.0\n",
      "2  2023-24             45.0            424.0\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the number of unique students ('StudentID') by 'AcYr' (Academic Year) and 'AdmitType'.\n",
    "aggregated_data = filtered_data.groupby(['AcYr', 'AdmitType']).agg({'StudentID': 'nunique'}).reset_index()\n",
    "\n",
    "# Rename the aggregated 'StudentID' column to 'HeadCount' to indicate student counts.\n",
    "aggregated_data = aggregated_data.rename(columns={'StudentID': 'HeadCount'})\n",
    "\n",
    "# Pivot the data to a wide format where each 'AdmitType' becomes a column, with student counts as values.\n",
    "wide_table_3 = aggregated_data.pivot_table(index='AcYr', columns=['AdmitType'], values='HeadCount', fill_value=0)\n",
    "\n",
    "# Rename columns by prefixing them with 'ABCD_' and suffixing them with '_Total' for clarity.\n",
    "wide_table_3.columns = ['ABCD_' + col + '_Total' for col in wide_table_3.columns]\n",
    "\n",
    "# Reset the index to convert 'AcYr' from the index back into a regular column.\n",
    "wide_table_3.reset_index(inplace=True)\n",
    "\n",
    "# (Optional) Display the first few rows and the shape of the final wide-format table for verification.\n",
    "# Uncomment the lines below to inspect the output.\n",
    "print(wide_table_3.head())\n",
    "#print(wide_table_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194b935-cd8b-4303-89a5-a895fd7acb75",
   "metadata": {},
   "source": [
    "# 5. Aggragate Students by 'AcYr', 'AdmitType', 'Ethnicity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13000783-f7bd-4ae1-89d5-192209173045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.508421Z",
     "iopub.status.busy": "2025-03-27T04:07:23.508421Z",
     "iopub.status.idle": "2025-03-27T04:07:23.522070Z",
     "shell.execute_reply": "2025-03-27T04:07:23.522070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AcYr  ABCD_Conc_African American  ABCD_Conc_Asian  ABCD_Conc_Filipino  \\\n",
      "0  2021-22                         0.0              1.0                 0.0   \n",
      "1  2022-23                         0.0              0.0                 1.0   \n",
      "2  2023-24                         2.0              3.0                 0.0   \n",
      "\n",
      "   ABCD_Conc_Latinx  ABCD_Conc_Multi-Ethnicity  ABCD_Conc_Unreported  \\\n",
      "0               5.0                        3.0                   0.0   \n",
      "1               1.0                        0.0                   0.0   \n",
      "2              17.0                        5.0                   2.0   \n",
      "\n",
      "   ABCD_Conc_White  ABCD_Dual_African American  ABCD_Dual_Asian  \\\n",
      "0              6.0                        20.0             69.0   \n",
      "1              2.0                        13.0             40.0   \n",
      "2             16.0                        29.0             80.0   \n",
      "\n",
      "   ABCD_Dual_Filipino  ABCD_Dual_Latinx  ABCD_Dual_Multi-Ethnicity  \\\n",
      "0                76.0             126.0                       42.0   \n",
      "1                35.0              87.0                       18.0   \n",
      "2                50.0             126.0                       37.0   \n",
      "\n",
      "   ABCD_Dual_Native American  ABCD_Dual_Pacific Islander  \\\n",
      "0                        0.0                         0.0   \n",
      "1                        0.0                         1.0   \n",
      "2                        2.0                         2.0   \n",
      "\n",
      "   ABCD_Dual_Unreported  ABCD_Dual_White  \n",
      "0                   3.0             86.0  \n",
      "1                   6.0             28.0  \n",
      "2                   5.0             93.0  \n"
     ]
    }
   ],
   "source": [
    "# Aggregate the number of unique students ('StudentID') by 'AcYr' (Academic Year), 'AdmitType', and 'Ethnicity'.\n",
    "aggregated_data = filtered_data.groupby(['AcYr', 'AdmitType', 'Ethnicity']).agg({'StudentID': 'nunique'}).reset_index()\n",
    "\n",
    "# Rename the aggregated 'StudentID' column to 'HeadCount' to represent the count of students.\n",
    "aggregated_data = aggregated_data.rename(columns={'StudentID': 'HeadCount'})\n",
    "\n",
    "# Pivot the data to a wide format where each combination of 'AdmitType' and 'Ethnicity' becomes a column, \n",
    "# with student counts ('HeadCount') as values.\n",
    "wide_table_4 = aggregated_data.pivot_table(index='AcYr', columns=['AdmitType', 'Ethnicity'], values='HeadCount', fill_value=0)\n",
    "\n",
    "# Flatten the hierarchical columns by combining 'AdmitType' and 'Ethnicity' into a single string.\n",
    "# Add a 'ABCD_' prefix to the column names for better identification.\n",
    "wide_table_4.columns = ['ABCD_' + '_'.join(col).strip() for col in wide_table_4.columns.values]\n",
    "\n",
    "# Reset the index to move 'AcYr' from the index back into a regular column.\n",
    "wide_table_4.reset_index(inplace=True)\n",
    "\n",
    "# (Optional) Display the first few rows and the shape of the final wide-format table for verification.\n",
    "# Uncomment the lines below to inspect the output.\n",
    "print(wide_table_4.head())\n",
    "# print(wide_table_4.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96704b8a-fad3-4aca-bcae-93536b4457b4",
   "metadata": {},
   "source": [
    "# 6. Combine All above Aggretated Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae1dbb7-3a57-4556-a638-6f54ed0a437e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.523100Z",
     "iopub.status.busy": "2025-03-27T04:07:23.523100Z",
     "iopub.status.idle": "2025-03-27T04:07:23.530741Z",
     "shell.execute_reply": "2025-03-27T04:07:23.530741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate tables horizontally based on common columns\n",
    "combined_table = pd.concat([wide_table_1.set_index(\"AcYr\"),\n",
    "                            wide_table_2.set_index(\"AcYr\"),\n",
    "                            wide_table_3.set_index(\"AcYr\"),\n",
    "                            wide_table_4.set_index(\"AcYr\")],\n",
    "                            axis=1)\n",
    "\n",
    "# Reset index to convert 'AcYr' back to columns\n",
    "combined_table.reset_index(inplace=True)\n",
    "combined_table.shape\n",
    "\n",
    "#drop duplicated columns, i.e,.'ABCD_Concurrent_African America' and 'ABCD_Conc_African America ' are duplicates, and so on \n",
    "#for example, 'SDCCD_Concurrent_African America' is a duplicate of 'SDCCD_Conc_African America ' \n",
    "# List of potential columns to drop\n",
    "columns_to_drop = [\n",
    "    'ABCD_Conc_Total', 'ABCD_Concurrent_African American',\n",
    "    'ABCD_Concurrent_Asian', 'ABCD_Concurrent_Filipino',\n",
    "    'ABCD_Concurrent_Latinx', 'ABCD_Concurrent_Multi-Ethnicity',\n",
    "    'ABCD_Concurrent_Native American', 'ABCD_Concurrent_Pacific Islander',\n",
    "    'ABCD_Concurrent_Unreported', 'ABCD_Concurrent_White'\n",
    "]\n",
    "\n",
    "# Filter the list to only include columns that exist in combined_table.columns\n",
    "columns_to_drop = [col for col in columns_to_drop if col in combined_table.columns]\n",
    "\n",
    "\n",
    "# Drop the specified columns\n",
    "combined_table.drop(columns=columns_to_drop, inplace=True)\n",
    "# Rename columns as needed\n",
    "combined_table = combined_table.rename(columns={'ABCD_Concurrent_Total': 'ABCD_Conc_Total'})\n",
    "\n",
    "\n",
    "\n",
    "# Adding the constant column \"ABCD\" with the value \"Overall\" as the first column\n",
    "combined_table.insert(0, \"ABCD\",\"Overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c074ee-b591-44df-981c-29183acbaca7",
   "metadata": {},
   "source": [
    "# 6. Import HighSchool Aggregated Data\n",
    "#### The HighSchool Aggregated Data was Produced by \"Sample_SpecialAdmit_Headcount_by_HighSchool.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21bec4bc-6833-4a7e-9d08-c4aa928fcd9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.533325Z",
     "iopub.status.busy": "2025-03-27T04:07:23.533325Z",
     "iopub.status.idle": "2025-03-27T04:07:23.721899Z",
     "shell.execute_reply": "2025-03-27T04:07:23.721541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path where your Highschool aggreated data is stored. \n",
    "# Replace \"sampledrive\\samplefolder\\samplefile\" with correct path (\"drive\\folder\\file\")\n",
    "file_path = r'C:\\Project Files\\CDE 2024 Python\\RP_Conference_Share\\Special Admit Heaadcount_by_HioghSchool.xlsx'\n",
    "\n",
    "# Check if file exists before reading\n",
    "if os.path.exists(file_path):\n",
    "    # Load data into a DataFrame\n",
    "    df_agg_HS = pd.read_excel(file_path)\n",
    "    print(\"File loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Error: The file at {file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ee506-4d3a-471b-9cb9-983f651a2387",
   "metadata": {},
   "source": [
    "#### Formatiing HighSchool Aggregated Data and the ablove Combined_table for concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940d4ce7-cc97-4ead-b99d-49c386558523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.721899Z",
     "iopub.status.busy": "2025-03-27T04:07:23.721899Z",
     "iopub.status.idle": "2025-03-27T04:07:23.727963Z",
     "shell.execute_reply": "2025-03-27T04:07:23.727963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Add \"Level of Aggregation\" column with value \"HighSchool\" in df_agg_HS\n",
    "df_agg_HS.insert(0, \"Level of Aggregation\", \"HighSchool\")\n",
    "\n",
    "# Step 2: Rename the 'ABCD' column in combined_table to 'School_ABCD' for consistency\n",
    "combined_table = combined_table.rename(columns={'ABCD': 'School_ABCD'})\n",
    "\n",
    "# Step 3: Add \"Level of Aggregation\" column with value \"Overall\" in combined_table\n",
    "combined_table.insert(0, \"Level of Aggregation\", \"Overall\")\n",
    "\n",
    "# Step 4: Concatenate the two dataframes df_agg_HS and combined_table vertically (along rows)\n",
    "df_combined = pd.concat([df_agg_HS, combined_table], ignore_index=True)\n",
    "\n",
    "# Optionally, display the first few rows of the combined dataframe\n",
    "# Uncomment the lines below to inspect the output.\n",
    "#print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c377900-fe52-4eb0-a43b-62c8bfaf01f7",
   "metadata": {},
   "source": [
    "# 7. Output the concatenated table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0265a9e8-cc24-4204-a524-518322a3e72c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T04:07:23.727963Z",
     "iopub.status.busy": "2025-03-27T04:07:23.727963Z",
     "iopub.status.idle": "2025-03-27T04:07:23.758978Z",
     "shell.execute_reply": "2025-03-27T04:07:23.758978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been saved to: C:\\Project Files\\CDE 2024 Python\\RP_Conference_Share\\Special Admit Heaadcount_combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the file path where the Excel file will be saved\n",
    "# Replace \"sampledrive\\samplefolder\\samplefile\" with correct path (\"drive\\folder\\file\")\n",
    "\n",
    "file_path = r'C:\\Project Files\\CDE 2024 Python\\RP_Conference_Share\\Special Admit Heaadcount_combined.xlsx'\n",
    "\n",
    "# Step 2: Save the aggregated data (df_combined) to an Excel file\n",
    "df_combined.to_excel(file_path, index=False)\n",
    "\n",
    "# Optionally, print a confirmation message\n",
    "print(f\"Combined data has been saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c266185-96ae-4b8d-a43f-5eedf214d014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
